{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['D:\\\\python\\\\Python3106-64', 'd:\\\\python\\\\Python3106-64\\\\python310.zip', 'd:\\\\python\\\\Python3106-64\\\\DLLs', 'd:\\\\python\\\\Python3106-64\\\\lib', '', 'C:\\\\Users\\\\10765\\\\AppData\\\\Roaming\\\\Python\\\\Python310\\\\site-packages', 'C:\\\\Users\\\\10765\\\\AppData\\\\Roaming\\\\Python\\\\Python310\\\\site-packages\\\\win32', 'C:\\\\Users\\\\10765\\\\AppData\\\\Roaming\\\\Python\\\\Python310\\\\site-packages\\\\win32\\\\lib', 'C:\\\\Users\\\\10765\\\\AppData\\\\Roaming\\\\Python\\\\Python310\\\\site-packages\\\\Pythonwin', 'd:\\\\python\\\\Python3106-64\\\\lib\\\\site-packages', 'd:\\\\python\\\\Python3106-64\\\\lib\\\\site-packages\\\\stable_diffusion-0.0.1-py3.10.egg', 'd:\\\\python\\\\Python3106-64\\\\lib\\\\site-packages\\\\k_diffusion-0.2.0.dev0-py3.10.egg', 'd:\\\\python\\\\Python3106-64\\\\lib\\\\site-packages\\\\wandb-0.17.5-py3.10.egg', 'd:\\\\python\\\\Python3106-64\\\\lib\\\\site-packages\\\\dctorch-0.1.2-py3.10.egg', 'd:\\\\python\\\\Python3106-64\\\\lib\\\\site-packages\\\\clip_anytorch-2.6.0-py3.10.egg', 'd:\\\\python\\\\Python3106-64\\\\lib\\\\site-packages\\\\setproctitle-1.3.3-py3.10-win-amd64.egg', 'd:\\\\python\\\\Python3106-64\\\\lib\\\\site-packages\\\\sentry_sdk-2.12.0-py3.10.egg', 'd:\\\\python\\\\Python3106-64\\\\lib\\\\site-packages\\\\platformdirs-4.2.2-py3.10.egg', 'd:\\\\python\\\\Python3106-64\\\\lib\\\\site-packages\\\\docker_pycreds-0.4.0-py3.10.egg', 'E:/tennis_v2/']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('E:/tennis_v2/')\n",
    "print(sys.path)\n",
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import pathlib\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from model.wasb import HRNet\n",
    "from utils.kalman_filter import KalmanFilter\n",
    "from model.bounce_detector import BounceDetector\n",
    "from collections import deque\n",
    "\n",
    "# from asset.tennis_v1.LoadData import resize_feature\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = 'E:/tennis_v2/'\n",
    "\n",
    "def preprocess_frame(frame, transform):\n",
    "    return transform(frame)\n",
    "\n",
    "def predict_ball_position(prev_positions, width, height):\n",
    "    if len(prev_positions) < 3:\n",
    "        return None\n",
    "    p_t = prev_positions[-1]\n",
    "    a_t = p_t - 2 * prev_positions[-2] + prev_positions[-3]\n",
    "    v_t = p_t - prev_positions[-2] + a_t\n",
    "    predicted_position = p_t + v_t + 0.5 * a_t\n",
    "    predicted_position = np.clip(predicted_position, [0, 0], [width, height])\n",
    "    return predicted_position\n",
    "\n",
    "def run_inference(input_path, output_path=\"\", overlay=False):\n",
    "    config = {\n",
    "        \"name\": \"hrnet\",\n",
    "        \"frames_in\": 3,\n",
    "        \"frames_out\": 3,\n",
    "        \"inp_height\": 288,\n",
    "        \"inp_width\": 512,\n",
    "        \"out_height\": 288,\n",
    "        \"out_width\": 512,\n",
    "        \"rgb_diff\": False,\n",
    "        \"out_scales\": [0],\n",
    "        \"MODEL\": {\n",
    "            \"EXTRA\": {\n",
    "                \"FINAL_CONV_KERNEL\": 1,\n",
    "                \"PRETRAINED_LAYERS\": ['*'],\n",
    "                \"STEM\": {\n",
    "                    \"INPLANES\": 64,\n",
    "                    \"STRIDES\": [1, 1]\n",
    "                },\n",
    "                \"STAGE1\": {\n",
    "                    \"NUM_MODULES\": 1,\n",
    "                    \"NUM_BRANCHES\": 1,\n",
    "                    \"BLOCK\": 'BOTTLENECK',\n",
    "                    \"NUM_BLOCKS\": [1],\n",
    "                    \"NUM_CHANNELS\": [32],\n",
    "                    \"FUSE_METHOD\": 'SUM'\n",
    "                },\n",
    "                \"STAGE2\": {\n",
    "                    \"NUM_MODULES\": 1,\n",
    "                    \"NUM_BRANCHES\": 2,\n",
    "                    \"BLOCK\": 'BASIC',\n",
    "                    \"NUM_BLOCKS\": [2, 2],\n",
    "                    \"NUM_CHANNELS\": [16, 32],\n",
    "                    \"FUSE_METHOD\": 'SUM'\n",
    "                },\n",
    "                \"STAGE3\": {\n",
    "                    \"NUM_MODULES\": 1,\n",
    "                    \"NUM_BRANCHES\": 3,\n",
    "                    \"BLOCK\": 'BASIC',\n",
    "                    \"NUM_BLOCKS\": [2, 2, 2],\n",
    "                    \"NUM_CHANNELS\": [16, 32, 64],\n",
    "                    \"FUSE_METHOD\": 'SUM'\n",
    "                },\n",
    "                \"STAGE4\": {\n",
    "                    \"NUM_MODULES\": 1,\n",
    "                    \"NUM_BRANCHES\": 4,\n",
    "                    \"BLOCK\": 'BASIC',\n",
    "                    \"NUM_BLOCKS\": [2, 2, 2, 2],\n",
    "                    \"NUM_CHANNELS\": [16, 32, 64, 128],\n",
    "                    \"FUSE_METHOD\": 'SUM'\n",
    "                },\n",
    "                \"DECONV\": {\n",
    "                    \"NUM_DECONVS\": 0,\n",
    "                    \"KERNEL_SIZE\": [],\n",
    "                    \"NUM_BASIC_BLOCKS\": 2\n",
    "                }\n",
    "            },\n",
    "            \"INIT_WEIGHTS\": True\n",
    "        },\n",
    "        \"model_path\": f\"{current_dir}/weights/wasb_tennis_best.pth\",  # Update with your model path\n",
    "    }\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize((config['inp_height'], config['inp_width'])),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "    model = HRNet(cfg=config).to(device)\n",
    "    checkpoint = torch.load(config['model_path'], map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'], strict=True)\n",
    "    model.eval()\n",
    "\n",
    "    # bounce model\n",
    "    # bounce_model = Model().to(device)\n",
    "    # bounce_model.load_state_dict(torch.load(f'{current_dir}/model_weight/model_state_dict_32_v3.pth'))\n",
    "    # bounce_model.eval()  # 设置为评估模式\n",
    "\n",
    "    bounce_detector = BounceDetector(f'{current_dir}/weights/ctb_regr_bounce.cbm')\n",
    "\n",
    "    cap = cv2.VideoCapture(input_path)\n",
    "\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    base_name = os.path.splitext(os.path.basename(input_path))[0]\n",
    "    if output_path == \"\":\n",
    "        output_video_path = os.path.join(os.path.dirname(output_path))\n",
    "        output_csv_path = os.path.join(os.path.dirname(input_path), f\"{base_name}_output_wasb.csv\")\n",
    "    else:\n",
    "        output_video_path = os.path.join(output_path)\n",
    "        output_csv_path = os.path.join(output_path, f\"{base_name}_output_wasb.csv\")\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_video_path, fourcc, 1, (width, height))\n",
    "    print(output_video_path)\n",
    "    frame_number = 0\n",
    "    frames_buffer = []\n",
    "\n",
    "    # 初始化卡尔曼滤波器\n",
    "    kf = KalmanFilter()\n",
    "    kf_mean, kf_covariance = None, None\n",
    "    stable_frames_threshold = 1\n",
    "    stable_ious_threshold = 0.1\n",
    "    kf_ratio_range = 1\n",
    "    kf_width_range = 8\n",
    "    stable_frames = 0\n",
    "    detection_queue = deque(maxlen=stable_frames_threshold)  # 检测队列\n",
    "\n",
    "    # bounce\n",
    "    coordinate_history = []\n",
    "    bounce_record = []\n",
    "    \n",
    "    # draw\n",
    "    points = None\n",
    "    \n",
    "    prev_positions = []\n",
    "    positions = []\n",
    "\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frames_buffer.append(frame)\n",
    "        if len(frames_buffer) == config['frames_in']:\n",
    "            # Preprocess the frames\n",
    "            frames_processed = [preprocess_frame(f, transform) for f in frames_buffer]\n",
    "            input_tensor = torch.cat(frames_processed, dim=0).unsqueeze(0).to(device)\n",
    "\n",
    "            # Perform inference\n",
    "            with torch.no_grad():\n",
    "                outputs = model(input_tensor)[0]  # Get the raw logits\n",
    "\n",
    "            detected = False\n",
    "            center_x, center_y, confidence = 0, 0, 0\n",
    "\n",
    "            for i in range(config['frames_out']):\n",
    "                output = outputs[0][i]\n",
    "                # Post-process the output\n",
    "                output = torch.sigmoid(output)  # Apply sigmoid to the output to get probabilities\n",
    "                heatmap = output.squeeze().cpu().numpy()\n",
    "                # print(output. shape, heatmap.shape)\n",
    "\n",
    "                heatmap = cv2.resize(heatmap, (width, height), interpolation=cv2.INTER_LINEAR)\n",
    "                heatmap = (heatmap > 0.5).astype(np.float32) * heatmap\n",
    "\n",
    "                if overlay:\n",
    "                    heatmap_normalized_visualization = cv2.normalize(heatmap, None, 0, 255, cv2.NORM_MINMAX)\n",
    "                    heatmap_normalized_visualization = heatmap_normalized_visualization.astype(np.uint8)\n",
    "                    # Apply color map to the heatmap\n",
    "                    heatmap_colored = cv2.applyColorMap(heatmap_normalized_visualization, cv2.COLORMAP_JET)\n",
    "                    # Overlay the heatmap on the original frame\n",
    "                    overlayed_frame = cv2.addWeighted(frames_buffer[i], 0.6, heatmap_colored, 0.4, 0)\n",
    "\n",
    "                # Find connected components\n",
    "                num_labels, labels_im, stats, centroids = cv2.connectedComponentsWithStats((heatmap > 0).astype(np.uint8), connectivity=8)\n",
    "\n",
    "                # Calculate centers of blobs\n",
    "                blob_centers = []\n",
    "                for j in range(1, num_labels):  # Skip the background label 0\n",
    "                    mask = labels_im == j\n",
    "                    blob_sum = heatmap[mask].sum()\n",
    "                    if blob_sum > 0:\n",
    "                        center_x = np.sum(np.where(mask)[1] * heatmap[mask]) / blob_sum\n",
    "                        center_y = np.sum(np.where(mask)[0] * heatmap[mask]) / blob_sum\n",
    "                        blob_centers.append((center_x, center_y, blob_sum))\n",
    "                    \n",
    "                if blob_centers:\n",
    "                    predicted_position = predict_ball_position(prev_positions, width, height)\n",
    "                    if predicted_position is not None:\n",
    "                        # Select the blob closest to the predicted position\n",
    "                        distances = [np.sqrt((x - predicted_position[0]) ** 2 + (y - predicted_position[1]) ** 2) for x, y, _ in blob_centers]\n",
    "                        closest_blob_idx = np.argmin(distances)\n",
    "                        center_x, center_y, confidence = blob_centers[closest_blob_idx]\n",
    "                    else:\n",
    "                        # Select the blob with the highest confidence if no prediction is available\n",
    "                        blob_centers.sort(key=lambda x: x[2], reverse=True)\n",
    "                        center_x, center_y, confidence = blob_centers[0]\n",
    "                    detected = True\n",
    "                    prev_positions.append(np.array([center_x, center_y]))\n",
    "                    if len(prev_positions) > 3:\n",
    "                        prev_positions.pop(0)\n",
    "                \n",
    "                \n",
    "                # Draw a circle on the detected ball\n",
    "                if detected:\n",
    "                    positions.append((center_x, center_y))\n",
    "                    detection_queue.append((center_x, center_y, confidence))\n",
    "                    color = (0, 255, 0)\n",
    "\n",
    "                else:\n",
    "                    # kalman filter predict\n",
    "                    if kf_mean is not None and kf_covariance is not None:\n",
    "                        # print(kf_mean)\n",
    "                        kf_mean, kf_covariance = kf.predict(kf_mean, kf_covariance)                        \n",
    "                        center_x, center_y = kf_mean[:2]\n",
    "                        color = (0, 255, 255)\n",
    "                \n",
    "                # Bounce\n",
    "                coordinate_history.append([center_x, center_y])\n",
    "                bounces = bounce_detector.predict([x[0] for x in coordinate_history], [x[1] for x in coordinate_history])\n",
    "                if bounces:\n",
    "                    bounce_record.append([center_x, center_y])\n",
    "                    coordinate_history = []\n",
    "                    # draw bounce\n",
    "                    print((center_x, center_y))\n",
    "                    cv2.circle(overlayed_frame if overlay else frames_buffer[i], (int(center_x), int(center_y)), 20, (255, 0, 0), 3)\n",
    "\n",
    "                ############################################################################################################\n",
    "                ####################################                Draw                   #################################\n",
    "                ############################################################################################################\n",
    "\n",
    "                ################################################################## test kalman filter #########################################################################\n",
    "                # if kf_mean is not None and kf_covariance is not None:\n",
    "                #     kf_mean, kf_covariance = kf.predict(kf_mean, kf_covariance)\n",
    "                #     cv2.rectangle(overlayed_frame if overlay else frames_buffer[0],(x1, y1), (x2, y2), (255, 255, 255), 2)\n",
    "                #     cv2.putText(overlayed_frame if overlay else frames_buffer[0], \"test_kalman\", (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "                ################################################################## test kalman filter #########################################################################\n",
    "                if (center_x is not None) and (center_y is not None) and (kf_mean is not None) and (kf_covariance is not None):\n",
    "                    # print(detected, kf_mean)\n",
    "                    x1, y1, x2, y2 =  kf.xyah_to_xyxy([center_x, center_y, kf_ratio_range, kf_width_range])\n",
    "                    x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "                    text = f\"{confidence:.2f}\"  # 格式化置信度到小数点后两位\n",
    "\n",
    "                    if overlay:\n",
    "                        # cv2.polylines(overlayed_frame, [points], isClosed=False, color=(0, 255, 255), thickness=2, lineType=cv2.LINE_AA)\n",
    "                        cv2.rectangle(overlayed_frame,(x1, y1), (x2, y2), color, 2)\n",
    "                        cv2.putText(overlayed_frame, text, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "   \n",
    "                        \n",
    "                    else:\n",
    "                        # cv2.polylines(overlayed_frame, [points], isClosed=False, color=(0, 255, 255), thickness=2, lineType=cv2.LINE_AA)\n",
    "                        cv2.rectangle(frames_buffer[i],(x1, y1), (x2, y2), color, 2)\n",
    "                        cv2.putText(frames_buffer[i], text, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "\n",
    "                ################################################################这个逻辑貌似不太理想############################################################################\n",
    "                # kalman filter\n",
    "                if len(detection_queue) == stable_frames_threshold:\n",
    "                    # 筛选可靠检测\n",
    "                    reliable_detections = [\n",
    "                        (x, y) for x, y, c in detection_queue if c > 0.25  # 例如，置信度阈值为 0.8\n",
    "                    ]\n",
    "\n",
    "                    # 如果有足够的可靠检测，则计算平均位置\n",
    "                    if len(reliable_detections) >= stable_frames_threshold // 2:  # 例如，至少需要一半的检测可靠\n",
    "                        avg_x = np.mean([x for x, y in reliable_detections])\n",
    "                        avg_y = np.mean([y for x, y in reliable_detections])\n",
    "                        if kf_mean is None and kf_covariance is None or stable_frames == 0:\n",
    "                            \"\"\"\n",
    "                            **初始化阶段**: 当self.kf_mean和self.kf_covariance尚未初始化,\n",
    "                            或者self.stable_frames为0时,使用第一个检测到的边界框来初始化卡尔曼滤波的状态(均值和协方差矩阵)\n",
    "                            此时直接选择IoU最高的掩码,并初始化KF。\n",
    "                            \"\"\"\n",
    "\n",
    "                            kf_mean, kf_covariance = kf.initiate(kf.xyxy_to_xyah([avg_x, avg_y, kf_ratio_range, kf_width_range]))\n",
    "                            stable_frames += 1\n",
    "                                # 清空队列，为下一次初始化做准备\n",
    "                    detection_queue.clear()\n",
    "                \n",
    "                    if stable_frames < stable_frames_threshold:\n",
    "                        \"\"\"\n",
    "                        当self.stable_frames小于阈值时,卡尔曼滤波进行预测,但不进行更新,除非当前帧的IoU足够高.\n",
    "                        此时,如果检测到的IoU超过阈值,则用当前边界框更新KF状态,并增加stable_frames的计数,否则重置计数。\n",
    "                        \"\"\"\n",
    "                    \n",
    "                        kf_mean, kf_covariance = kf.predict(kf_mean, kf_covariance)\n",
    "                        predict_iou = kf._compute_iou(kf.xyah_to_xyxy([center_x, center_y, kf_ratio_range, kf_width_range]), kf.xyah_to_xyxy(kf_mean[:4]))\n",
    "\n",
    "                        if predict_iou > stable_ious_threshold:\n",
    "                            kf_mean, kf_covariance = kf.update(kf_mean, kf_covariance, [center_x, center_y, kf_ratio_range, kf_width_range])\n",
    "                            stable_frames += 1\n",
    "                        else:\n",
    "                            stable_frames -= 1\n",
    "                    else:\n",
    "                        \"\"\"\n",
    "                        **稳定后的更新阶段**:当stable_frames达到阈值后,KF进入正常预测和更新循环.\n",
    "                        每次预测后, 计算当前多个候选掩码的边界框与KF预测的边界框之间的IoU, \n",
    "                        然后结合KF的IoU和模型预测的IoU,加权后选择最佳掩码,并更新KF的状态。\n",
    "                        \"\"\"\n",
    "                                            \n",
    "                        kf_mean, kf_covariance = kf.predict(kf_mean, kf_covariance)\n",
    "                        kf_mean, kf_covariance = kf.update(kf_mean, kf_covariance, [center_x, center_y, kf_ratio_range, kf_width_range])\n",
    "                ###############################################################################################################################################################\n",
    "                \n",
    "                if len(positions) > 12:\n",
    "                    positions.pop(0)\n",
    "                # Write the frame to the output video and save the coordinates\n",
    "                out.write(overlayed_frame if overlay else frames_buffer[0])\n",
    "                frame_number += 1  \n",
    "            frames_buffer = []  # Clear the buffer for the next set of frames\n",
    "\n",
    "    # Release everything if job is finished\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    # # Save coordinates to CSV file\n",
    "    # coordinates_df = pd.DataFrame(coordinates, columns=[\"frame_number\", \"detected\", \"x\", \"y\", \"confidence (blob size)\"])\n",
    "    # coordinates_df.to_csv(output_csv_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e:/tennis_v2/inference/HRnet_test_02.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No objects info loaded\n",
      "No objects info loaded\n",
      "No objects info loaded\n",
      "No objects info loaded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "{8}\n",
      "(358.281957143835, 410.7941550543449)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No objects info loaded\n",
      "No objects info loaded\n",
      "No objects info loaded\n",
      "No objects info loaded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "{53}\n",
      "(742.2607543669113, 126.67091756902694)\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No objects info loaded\n",
      "No objects info loaded\n",
      "No objects info loaded\n",
      "No objects info loaded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "{35}\n",
      "(870.9274720622983, 520.0470786870469)\n",
      "set()\n",
      "set()\n",
      "set()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No objects info loaded\n",
      "No objects info loaded\n",
      "No objects info loaded\n",
      "No objects info loaded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "{40}\n",
      "(451.7940444299371, 204.41593997781547)\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No objects info loaded\n",
      "No objects info loaded\n",
      "No objects info loaded\n",
      "No objects info loaded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "{30}\n",
      "(772.0226700120511, 412.13914992897594)\n",
      "set()\n",
      "set()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No objects info loaded\n",
      "No objects info loaded\n",
      "No objects info loaded\n",
      "No objects info loaded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "{38}\n",
      "(521.7231728518086, 131.34931108406283)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No objects info loaded\n",
      "No objects info loaded\n",
      "No objects info loaded\n",
      "No objects info loaded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "{11}\n",
      "(533.6294366348918, 87.15525009695602)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No objects info loaded\n",
      "No objects info loaded\n",
      "No objects info loaded\n",
      "No objects info loaded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "{18}\n",
      "(803.4724529419332, 426.7265836043146)\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No objects info loaded\n",
      "No objects info loaded\n",
      "No objects info loaded\n",
      "No objects info loaded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "{27}\n",
      "(495.9622085791599, 143.51696763737775)\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No objects info loaded\n",
      "No objects info loaded\n",
      "No objects info loaded\n",
      "No objects info loaded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "{30}\n",
      "(810.896548702823, 392.1378179187956)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No objects info loaded\n",
      "No objects info loaded\n",
      "No objects info loaded\n",
      "No objects info loaded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "{37}\n",
      "(486.8900013195773, 288.9045988101383)\n"
     ]
    }
   ],
   "source": [
    "video_input_path = 'e:/TennisProject-main/inference/test_02.mp4'\n",
    "video_output_path = 'e:/tennis_v2/inference/HRnet_' + video_input_path.split('/')[-1]\n",
    "run_inference(video_input_path, video_output_path, overlay=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

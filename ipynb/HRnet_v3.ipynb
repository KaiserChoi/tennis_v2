{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(\"D:/tennis_v2/\")\n",
    "\n",
    "import cv2\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from model.wasb import HRNet\n",
    "from utils.interpolater import TrajectoryInterpolator\n",
    "from utils.kalman_filter import KalmanFilter\n",
    "from utils.draw import Draw_video\n",
    "from assets.bounce import detect_bounces, draw_cross\n",
    "from assets.person_detector import PersonDetector\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Constants and Configuration ---\n",
    "CURRENT_DIR = 'D:/tennis_v2/'\n",
    "MODEL_PATH = f\"{CURRENT_DIR}/weights/wasb_tennis_best.pth\"\n",
    "# BOUNCE_DETECTOR_PATH = f\"{CURRENT_DIR}/weights/ctb_regr_bounce.cbm\"\n",
    "DELAY = 15  # 延迟帧数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = 'D:/tennis_v2/'\n",
    "\n",
    "def preprocess_frame(frame, transform):\n",
    "    return transform(frame)\n",
    "\n",
    "def predict_ball_position(prev_positions, width, height):\n",
    "    if len(prev_positions) < 3:\n",
    "        return None\n",
    "    p_t = prev_positions[-1]\n",
    "    a_t = p_t - 2 * prev_positions[-2] + prev_positions[-3]\n",
    "    v_t = p_t - prev_positions[-2] + a_t\n",
    "    predicted_position = p_t + v_t + 0.5 * a_t\n",
    "    predicted_position = np.clip(predicted_position, [0, 0], [width, height])\n",
    "    return predicted_position\n",
    "\n",
    "def run_inference(input_path, output_path=\"\", output_csv_path=\"\", overlay=False):\n",
    "    config = {\n",
    "        \"name\": \"hrnet\",\n",
    "        \"frames_in\": 3,\n",
    "        \"frames_out\": 3,\n",
    "        \"inp_height\": 288,\n",
    "        \"inp_width\": 512,\n",
    "        \"out_height\": 288,\n",
    "        \"out_width\": 512,\n",
    "        \"rgb_diff\": False,\n",
    "        \"out_scales\": [0],\n",
    "        \"MODEL\": {\n",
    "            \"EXTRA\": {\n",
    "                \"FINAL_CONV_KERNEL\": 1,\n",
    "                \"PRETRAINED_LAYERS\": ['*'],\n",
    "                \"STEM\": {\n",
    "                    \"INPLANES\": 64,\n",
    "                    \"STRIDES\": [1, 1]\n",
    "                },\n",
    "                \"STAGE1\": {\n",
    "                    \"NUM_MODULES\": 1,\n",
    "                    \"NUM_BRANCHES\": 1,\n",
    "                    \"BLOCK\": 'BOTTLENECK',\n",
    "                    \"NUM_BLOCKS\": [1],\n",
    "                    \"NUM_CHANNELS\": [32],\n",
    "                    \"FUSE_METHOD\": 'SUM'\n",
    "                },\n",
    "                \"STAGE2\": {\n",
    "                    \"NUM_MODULES\": 1,\n",
    "                    \"NUM_BRANCHES\": 2,\n",
    "                    \"BLOCK\": 'BASIC',\n",
    "                    \"NUM_BLOCKS\": [2, 2],\n",
    "                    \"NUM_CHANNELS\": [16, 32],\n",
    "                    \"FUSE_METHOD\": 'SUM'\n",
    "                },\n",
    "                \"STAGE3\": {\n",
    "                    \"NUM_MODULES\": 1,\n",
    "                    \"NUM_BRANCHES\": 3,\n",
    "                    \"BLOCK\": 'BASIC',\n",
    "                    \"NUM_BLOCKS\": [2, 2, 2],\n",
    "                    \"NUM_CHANNELS\": [16, 32, 64],\n",
    "                    \"FUSE_METHOD\": 'SUM'\n",
    "                },\n",
    "                \"STAGE4\": {\n",
    "                    \"NUM_MODULES\": 1,\n",
    "                    \"NUM_BRANCHES\": 4,\n",
    "                    \"BLOCK\": 'BASIC',\n",
    "                    \"NUM_BLOCKS\": [2, 2, 2, 2],\n",
    "                    \"NUM_CHANNELS\": [16, 32, 64, 128],\n",
    "                    \"FUSE_METHOD\": 'SUM'\n",
    "                },\n",
    "                \"DECONV\": {\n",
    "                    \"NUM_DECONVS\": 0,\n",
    "                    \"KERNEL_SIZE\": [],\n",
    "                    \"NUM_BASIC_BLOCKS\": 2\n",
    "                }\n",
    "            },\n",
    "            \"INIT_WEIGHTS\": True\n",
    "        },\n",
    "        \"model_path\": f\"{current_dir}/weights/wasb_tennis_best.pth\",  # Update with your model path\n",
    "    }\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize((config['inp_height'], config['inp_width'])),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "    model = HRNet(cfg=config).to(device)\n",
    "    checkpoint = torch.load(config['model_path'], map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'], strict=True)\n",
    "    model.eval()\n",
    "\n",
    "    person_model = PersonDetector()\n",
    "    player_columns = [\"frame_number\", \"player1_x1\", \"player1_y1\", \"player1_x2\", \"player1_y2\",\n",
    "                      \"player2_x3\", \"player2_y3\", \"player2_x4\", \"player2_y4\"]\n",
    "    \n",
    "    cap = cv2.VideoCapture(input_path)\n",
    "\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    base_name = os.path.splitext(os.path.basename(input_path))[0]\n",
    "    if output_path == \"\":\n",
    "        output_video_path = os.path.join(os.path.dirname(output_path))\n",
    "    else:\n",
    "        output_video_path = os.path.join(output_path)\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_video_path, fourcc, 1, (width, height))   # fps\n",
    "    print(output_video_path)\n",
    "    frame_number = 0\n",
    "    frames_buffer = []\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    # detect people\n",
    "    frame_number_outer = 0\n",
    "    player_data = []\n",
    "\n",
    "    # kalman\n",
    "    kf = KalmanFilter()\n",
    "    kf_ratio_range = 1\n",
    "    kf_width_range = 8\n",
    "\n",
    "    interpolator = TrajectoryInterpolator()\n",
    "    need_interpolator = False\n",
    "    interpolator_ranage = 10\n",
    "    interpolator_count = []\n",
    "    interpolator_start_frame = None\n",
    "\n",
    "\n",
    "    # bounce\n",
    "    coordinate_history = []\n",
    "    frame_history = []   # save the frame, because some frame can not detect the ball, have to predict (x, y) by the context\n",
    "    \n",
    "    prev_positions = [] # for blob select\n",
    "    visited = {}\n",
    "\n",
    "    # draw\n",
    "    draw_video = Draw_video()\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frames_buffer.append(frame)\n",
    "        frame_history.append(frame)\n",
    "\n",
    "\n",
    "        #####################################################################################################################\n",
    "        ########################################           detect people               ######################################\n",
    "        #####################################################################################################################\n",
    "\n",
    "        player_result = person_model.track_players(frame, frame_number_outer)\n",
    "        x1, y1, x2, y2, x3, y3, x4, y4 = player_result[1:]\n",
    "        player_data.append(player_result)\n",
    "        frame_number_outer += 1\n",
    "\n",
    "\n",
    "\n",
    "        #####################################################################################################################\n",
    "        ########################################           detect tennis ball          ######################################\n",
    "        #####################################################################################################################\n",
    "\n",
    "        if len(frames_buffer) == config['frames_in']:\n",
    "            # Preprocess the frames\n",
    "            frames_processed = [preprocess_frame(f, transform) for f in frames_buffer]\n",
    "            input_tensor = torch.cat(frames_processed, dim=0).unsqueeze(0).to(device)\n",
    "\n",
    "            # Perform inference\n",
    "            with torch.no_grad():\n",
    "                outputs = model(input_tensor)[0]  # Get the raw logits\n",
    "\n",
    "            detected = False\n",
    "            center_x, center_y, confidence = 0, 0, 0\n",
    "\n",
    "            for i in range(config['frames_out']):\n",
    "                output = outputs[0][i]\n",
    "                # Post-process the output\n",
    "                output = torch.sigmoid(output)  # Apply sigmoid to the output to get probabilities\n",
    "                heatmap = output.squeeze().cpu().numpy()\n",
    "                # print(output. shape, heatmap.shape)\n",
    "\n",
    "                heatmap = cv2.resize(heatmap, (width, height), interpolation=cv2.INTER_LINEAR)\n",
    "                heatmap = (heatmap > 0.5).astype(np.float32) * heatmap\n",
    "\n",
    "                if overlay:\n",
    "                    heatmap_normalized_visualization = cv2.normalize(heatmap, None, 0, 255, cv2.NORM_MINMAX)\n",
    "                    heatmap_normalized_visualization = heatmap_normalized_visualization.astype(np.uint8)\n",
    "                    # Apply color map to the heatmap\n",
    "                    heatmap_colored = cv2.applyColorMap(heatmap_normalized_visualization, cv2.COLORMAP_JET)\n",
    "                    # Overlay the heatmap on the original frame\n",
    "                    overlayed_frame = cv2.addWeighted(frames_buffer[i], 0.6, heatmap_colored, 0.4, 0)\n",
    "\n",
    "                # Find connected components\n",
    "                num_labels, labels_im, stats, centroids = cv2.connectedComponentsWithStats((heatmap > 0).astype(np.uint8), connectivity=8)\n",
    "\n",
    "                # Calculate centers of blobs\n",
    "                blob_centers = []\n",
    "                for j in range(1, num_labels):  # Skip the background label 0\n",
    "                    mask = labels_im == j\n",
    "                    blob_sum = heatmap[mask].sum()\n",
    "                    if blob_sum > 0:\n",
    "                        center_x = np.sum(np.where(mask)[1] * heatmap[mask]) / blob_sum\n",
    "                        center_y = np.sum(np.where(mask)[0] * heatmap[mask]) / blob_sum\n",
    "                        blob_centers.append((center_x, center_y, blob_sum))\n",
    "                    \n",
    "                if blob_centers:\n",
    "                    predicted_position = predict_ball_position(prev_positions, width, height)\n",
    "                    if predicted_position is not None:\n",
    "                        # Select the blob closest to the predicted position\n",
    "                        distances = [np.sqrt((x - predicted_position[0]) ** 2 + (y - predicted_position[1]) ** 2) for x, y, _ in blob_centers]\n",
    "                        closest_blob_idx = np.argmin(distances)\n",
    "                        center_x, center_y, confidence = blob_centers[closest_blob_idx]\n",
    "                    else:\n",
    "                        # Select the blob with the highest confidence if no prediction is available\n",
    "                        blob_centers.sort(key=lambda x: x[2], reverse=True)\n",
    "                        center_x, center_y, confidence = blob_centers[0]\n",
    "                    detected = True\n",
    "                    prev_positions.append(np.array([center_x, center_y]))\n",
    "                    if len(prev_positions) > 3:\n",
    "                        prev_positions.pop(0)\n",
    "                \n",
    "                \n",
    "                \"\"\" if the frame can not detect the tennis, it will wait until the detect comeout 3 times and then fit the miss tennis coordinate \"\"\"\n",
    "                if detected == True :\n",
    "                    coordinate_history.append([center_x, center_y])\n",
    "                    if not need_interpolator:\n",
    "                        color = (0, 255, 0)\n",
    "                        x1, y1, x2, y2 =  kf.xyah_to_xyxy([center_x, center_y, kf_ratio_range, kf_width_range])\n",
    "                        x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "                        text = f\"{confidence:.2f}\"\n",
    "\n",
    "                        # cv2.polylines(overlayed_frame, [points], isClosed=False, color=(0, 255, 255), thickness=2, lineType=cv2.LINE_AA)\n",
    "                        cv2.rectangle(frame_history[-config['frames_out'] + i],(x1, y1), (x2, y2), color, 2)\n",
    "                        cv2.putText(frame_history[-config['frames_out'] + i], text, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)              \n",
    "                    else:\n",
    "                        interpolator_count.append([center_x, center_y])\n",
    "                        \n",
    "\n",
    "                else:\n",
    "                    coordinate_history.append([None, None])\n",
    "                    if not need_interpolator:\n",
    "                        need_interpolator = True\n",
    "                        interpolator_start_frame = frame_number\n",
    "                    else:\n",
    "                        interpolator_ranage = min(interpolator_ranage + 1, 20)\n",
    "                    \n",
    "                if need_interpolator:\n",
    "                    if len(interpolator_count) >= interpolator_ranage:\n",
    "                        color = (0, 255, 255)\n",
    "                        inter_trac = interpolator.update_detection_history(coordinate_history, interpolator_start_frame, frame_number)\n",
    "                        for f in range(interpolator_start_frame, frame_number):\n",
    "                            x, y = inter_trac.loc[f, 'x'], inter_trac.loc[f, 'y']\n",
    "                            coordinate_history[f][0], coordinate_history[f][1] =  x, y\n",
    "                            x1, y1, x2, y2 =  kf.xyah_to_xyxy([x, y, kf_ratio_range, kf_width_range])\n",
    "                            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "                            cv2.rectangle(frame_history[f],(x1, y1), (x2, y2), color, 2)\n",
    "                        interpolator_count = []\n",
    "                        need_interpolator = False\n",
    "                        interpolator_ranage = 10\n",
    "                \n",
    "        #####################################################################################################################\n",
    "        ########################################           detect bounce&shot          ######################################\n",
    "        #####################################################################################################################\n",
    "                if frame_number > 0 and frame_number % 30 == 0 and not need_interpolator: # and not need_interpolator\n",
    "                    trajectory = pd.DataFrame(coordinate_history, columns=['x', 'y'])\n",
    "                    bounces, ix_5, x,y, ie = detect_bounces(trajectory) # output_csv_path, path_to_video=output_path, path_to_output_video='d:/tennis_v2/inference/HRnetv3_test_03_with_bounce.mp4'\n",
    "                    \n",
    "                    for key, value in ie.items():\n",
    "                        if key not in visited:\n",
    "                            visited[key] = value\n",
    "\n",
    "                \n",
    "                \"\"\" draw bounce \"\"\"\n",
    "                for item in visited:\n",
    "                    if \n",
    "                    if ie_dict[item] == 'shot':\n",
    "                        color = (0, 255, 0) \n",
    "                    elif ie_dict[item] == 'bounce':\n",
    "                        color = (0, 0, 255)\n",
    "                    else:\n",
    "                        color = (255, 0, 0)\n",
    "                    # draw_cross(frame_history, x[item], y[item], color=color)\n",
    "                \"\"\" draw bounce \"\"\"\n",
    "\n",
    "                print(f'frame_number: {frame_number}/{frame_count}, detected: {detected}')\n",
    "                frame_number += 1\n",
    "            frames_buffer = []  # Clear the buffer for the next set of frames\n",
    "\n",
    "    for frame in frame_history:\n",
    "        out.write(frame)\n",
    "\n",
    "    # Release everything if job is finished\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "        # print(bounces)\n",
    "    # if len(coordinate_history) > 15:\n",
    "    #     print((center_x, center_y), coordinate_history)\n",
    "    #     bounce_data = resize_feature(np.array(coordinate_history))\n",
    "    #     bounces = bounce_detector.predict(bounce_data[:, 0], bounce_data[:, 1])\n",
    "    #     if bounces:\n",
    "    #         bounce_record.append([center_x, center_y])\n",
    "    #         coordinate_history = []\n",
    "    #         # draw bounce\n",
    "    #         cv2.circle(overlayed_frame if overlay else frames_buffer[i], (int(center_x), int(center_y)), 20, (255, 0, 0), 3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:/tennis_v2/inference/HRnetv3_30f_test_02.mp4\n",
      "frame_number: 0/361, detected: True\n",
      "frame_number: 1/361, detected: True\n",
      "frame_number: 2/361, detected: True\n",
      "frame_number: 3/361, detected: True\n",
      "frame_number: 4/361, detected: True\n",
      "frame_number: 5/361, detected: True\n",
      "frame_number: 6/361, detected: True\n",
      "frame_number: 7/361, detected: True\n",
      "frame_number: 8/361, detected: True\n",
      "frame_number: 9/361, detected: True\n",
      "frame_number: 10/361, detected: True\n",
      "frame_number: 11/361, detected: True\n",
      "frame_number: 12/361, detected: True\n",
      "frame_number: 13/361, detected: True\n",
      "frame_number: 14/361, detected: True\n",
      "frame_number: 15/361, detected: True\n",
      "frame_number: 16/361, detected: True\n",
      "frame_number: 17/361, detected: True\n",
      "frame_number: 18/361, detected: True\n",
      "frame_number: 19/361, detected: True\n",
      "frame_number: 20/361, detected: True\n",
      "frame_number: 21/361, detected: False\n",
      "frame_number: 22/361, detected: True\n",
      "frame_number: 23/361, detected: True\n",
      "frame_number: 24/361, detected: True\n",
      "frame_number: 25/361, detected: True\n",
      "frame_number: 26/361, detected: True\n",
      "frame_number: 27/361, detected: True\n",
      "frame_number: 28/361, detected: True\n",
      "frame_number: 29/361, detected: True\n",
      "frame_number: 30/361, detected: True\n",
      "frame_number: 31/361, detected: True\n",
      "frame_number: 32/361, detected: True\n",
      "frame_number: 33/361, detected: True\n",
      "frame_number: 34/361, detected: True\n",
      "frame_number: 35/361, detected: True\n",
      "frame_number: 36/361, detected: True\n",
      "frame_number: 37/361, detected: True\n",
      "frame_number: 38/361, detected: True\n",
      "frame_number: 39/361, detected: True\n",
      "frame_number: 40/361, detected: True\n",
      "frame_number: 41/361, detected: True\n",
      "frame_number: 42/361, detected: True\n",
      "frame_number: 43/361, detected: True\n",
      "frame_number: 44/361, detected: True\n",
      "frame_number: 45/361, detected: True\n",
      "frame_number: 46/361, detected: True\n",
      "frame_number: 47/361, detected: True\n",
      "frame_number: 48/361, detected: True\n",
      "frame_number: 49/361, detected: True\n",
      "frame_number: 50/361, detected: True\n",
      "frame_number: 51/361, detected: True\n",
      "frame_number: 52/361, detected: True\n",
      "frame_number: 53/361, detected: True\n",
      "frame_number: 54/361, detected: True\n",
      "frame_number: 55/361, detected: True\n",
      "frame_number: 56/361, detected: True\n",
      "frame_number: 57/361, detected: True\n",
      "frame_number: 58/361, detected: True\n",
      "frame_number: 59/361, detected: True\n",
      "61 61 63 {8: 'bounce', 17: 'shot'}\n",
      "frame_number: 60/361, detected: True\n",
      "frame_number: 61/361, detected: True\n",
      "frame_number: 62/361, detected: True\n",
      "frame_number: 63/361, detected: True\n",
      "frame_number: 64/361, detected: True\n",
      "frame_number: 65/361, detected: True\n",
      "frame_number: 66/361, detected: True\n",
      "frame_number: 67/361, detected: True\n",
      "frame_number: 68/361, detected: True\n",
      "frame_number: 69/361, detected: True\n",
      "frame_number: 70/361, detected: True\n",
      "frame_number: 71/361, detected: True\n",
      "frame_number: 72/361, detected: True\n",
      "frame_number: 73/361, detected: True\n",
      "frame_number: 74/361, detected: True\n",
      "frame_number: 75/361, detected: True\n",
      "frame_number: 76/361, detected: True\n",
      "frame_number: 77/361, detected: True\n",
      "frame_number: 78/361, detected: True\n",
      "frame_number: 79/361, detected: True\n",
      "frame_number: 80/361, detected: True\n",
      "frame_number: 81/361, detected: True\n",
      "frame_number: 82/361, detected: True\n",
      "frame_number: 83/361, detected: True\n",
      "frame_number: 84/361, detected: True\n",
      "frame_number: 85/361, detected: True\n",
      "frame_number: 86/361, detected: True\n",
      "frame_number: 87/361, detected: True\n",
      "frame_number: 88/361, detected: True\n",
      "frame_number: 89/361, detected: True\n",
      "91 91 93 {8: 'bounce', 17: 'shot', 64: 'bounce', 78: 'shot'}\n",
      "frame_number: 90/361, detected: True\n",
      "frame_number: 91/361, detected: True\n",
      "frame_number: 92/361, detected: True\n",
      "frame_number: 93/361, detected: True\n",
      "frame_number: 94/361, detected: True\n",
      "frame_number: 95/361, detected: True\n",
      "frame_number: 96/361, detected: True\n",
      "frame_number: 97/361, detected: True\n",
      "frame_number: 98/361, detected: True\n",
      "frame_number: 99/361, detected: True\n",
      "frame_number: 100/361, detected: True\n",
      "frame_number: 101/361, detected: True\n",
      "frame_number: 102/361, detected: True\n",
      "frame_number: 103/361, detected: True\n",
      "frame_number: 104/361, detected: True\n",
      "frame_number: 105/361, detected: True\n",
      "frame_number: 106/361, detected: True\n",
      "frame_number: 107/361, detected: True\n",
      "frame_number: 108/361, detected: True\n",
      "frame_number: 109/361, detected: True\n",
      "frame_number: 110/361, detected: True\n",
      "frame_number: 111/361, detected: True\n",
      "frame_number: 112/361, detected: True\n",
      "frame_number: 113/361, detected: True\n",
      "frame_number: 114/361, detected: True\n",
      "frame_number: 115/361, detected: True\n",
      "frame_number: 116/361, detected: True\n",
      "frame_number: 117/361, detected: True\n",
      "frame_number: 118/361, detected: True\n",
      "frame_number: 119/361, detected: True\n",
      "121 121 123 {8: 'bounce', 17: 'shot', 64: 'bounce', 74: 'shot', 102: 'bounce', 114: 'shot'}\n",
      "frame_number: 120/361, detected: True\n",
      "frame_number: 121/361, detected: True\n",
      "frame_number: 122/361, detected: True\n",
      "frame_number: 123/361, detected: True\n",
      "frame_number: 124/361, detected: True\n",
      "frame_number: 125/361, detected: True\n",
      "frame_number: 126/361, detected: True\n",
      "frame_number: 127/361, detected: True\n",
      "frame_number: 128/361, detected: True\n",
      "frame_number: 129/361, detected: True\n",
      "frame_number: 130/361, detected: True\n",
      "frame_number: 131/361, detected: True\n",
      "frame_number: 132/361, detected: True\n",
      "frame_number: 133/361, detected: True\n",
      "frame_number: 134/361, detected: True\n",
      "frame_number: 135/361, detected: True\n",
      "frame_number: 136/361, detected: True\n",
      "frame_number: 137/361, detected: True\n",
      "frame_number: 138/361, detected: True\n",
      "frame_number: 139/361, detected: True\n",
      "frame_number: 140/361, detected: True\n",
      "frame_number: 141/361, detected: True\n",
      "frame_number: 142/361, detected: True\n",
      "frame_number: 143/361, detected: True\n",
      "frame_number: 144/361, detected: True\n",
      "frame_number: 145/361, detected: True\n",
      "frame_number: 146/361, detected: True\n",
      "frame_number: 147/361, detected: True\n",
      "frame_number: 148/361, detected: True\n",
      "frame_number: 149/361, detected: True\n",
      "151 151 153 {8: 'bounce', 17: 'shot', 64: 'bounce', 74: 'shot', 102: 'bounce', 114: 'shot', 145: 'bounce'}\n",
      "frame_number: 150/361, detected: True\n",
      "frame_number: 151/361, detected: True\n",
      "frame_number: 152/361, detected: True\n",
      "frame_number: 153/361, detected: True\n",
      "frame_number: 154/361, detected: True\n",
      "frame_number: 155/361, detected: True\n",
      "frame_number: 156/361, detected: True\n",
      "frame_number: 157/361, detected: True\n",
      "frame_number: 158/361, detected: True\n",
      "frame_number: 159/361, detected: True\n",
      "frame_number: 160/361, detected: True\n",
      "frame_number: 161/361, detected: True\n",
      "frame_number: 162/361, detected: False\n",
      "frame_number: 163/361, detected: False\n",
      "frame_number: 164/361, detected: False\n",
      "frame_number: 165/361, detected: True\n",
      "frame_number: 166/361, detected: True\n",
      "frame_number: 167/361, detected: True\n",
      "frame_number: 168/361, detected: True\n",
      "frame_number: 169/361, detected: True\n",
      "frame_number: 170/361, detected: True\n",
      "frame_number: 171/361, detected: True\n",
      "frame_number: 172/361, detected: True\n",
      "frame_number: 173/361, detected: True\n",
      "frame_number: 174/361, detected: True\n",
      "frame_number: 175/361, detected: True\n",
      "frame_number: 176/361, detected: True\n",
      "frame_number: 177/361, detected: True\n",
      "frame_number: 178/361, detected: True\n",
      "frame_number: 179/361, detected: True\n",
      "181 181 183 {8: 'bounce', 17: 'shot', 64: 'bounce', 74: 'shot', 102: 'bounce', 114: 'shot', 145: 'bounce', 161: 'shot', 179: 'bounce'}\n",
      "frame_number: 180/361, detected: True\n",
      "frame_number: 181/361, detected: True\n",
      "frame_number: 182/361, detected: True\n",
      "frame_number: 183/361, detected: True\n",
      "frame_number: 184/361, detected: True\n",
      "frame_number: 185/361, detected: True\n",
      "frame_number: 186/361, detected: True\n",
      "frame_number: 187/361, detected: True\n",
      "frame_number: 188/361, detected: True\n",
      "frame_number: 189/361, detected: False\n",
      "frame_number: 190/361, detected: False\n",
      "frame_number: 191/361, detected: False\n",
      "frame_number: 192/361, detected: False\n",
      "frame_number: 193/361, detected: True\n",
      "frame_number: 194/361, detected: True\n",
      "frame_number: 195/361, detected: True\n",
      "frame_number: 196/361, detected: True\n",
      "frame_number: 197/361, detected: True\n",
      "frame_number: 198/361, detected: True\n",
      "frame_number: 199/361, detected: True\n",
      "frame_number: 200/361, detected: True\n",
      "frame_number: 201/361, detected: True\n",
      "frame_number: 202/361, detected: True\n",
      "frame_number: 203/361, detected: True\n",
      "frame_number: 204/361, detected: True\n",
      "frame_number: 205/361, detected: True\n",
      "frame_number: 206/361, detected: True\n",
      "frame_number: 207/361, detected: True\n",
      "frame_number: 208/361, detected: True\n",
      "frame_number: 209/361, detected: True\n",
      "211 211 213 {8: 'bounce', 17: 'shot', 64: 'bounce', 74: 'shot', 102: 'bounce', 114: 'shot', 145: 'bounce', 161: 'shot', 178: 'bounce', 193: 'shot'}\n",
      "frame_number: 210/361, detected: True\n",
      "frame_number: 211/361, detected: True\n",
      "frame_number: 212/361, detected: True\n",
      "frame_number: 213/361, detected: True\n",
      "frame_number: 214/361, detected: True\n",
      "frame_number: 215/361, detected: True\n",
      "frame_number: 216/361, detected: True\n",
      "frame_number: 217/361, detected: True\n",
      "frame_number: 218/361, detected: True\n",
      "frame_number: 219/361, detected: True\n",
      "frame_number: 220/361, detected: True\n",
      "frame_number: 221/361, detected: True\n",
      "frame_number: 222/361, detected: True\n",
      "frame_number: 223/361, detected: True\n",
      "frame_number: 224/361, detected: True\n",
      "frame_number: 225/361, detected: True\n",
      "frame_number: 226/361, detected: True\n",
      "frame_number: 227/361, detected: True\n",
      "frame_number: 228/361, detected: True\n",
      "frame_number: 229/361, detected: True\n",
      "frame_number: 230/361, detected: True\n",
      "frame_number: 231/361, detected: True\n",
      "frame_number: 232/361, detected: True\n",
      "frame_number: 233/361, detected: True\n",
      "frame_number: 234/361, detected: False\n",
      "frame_number: 235/361, detected: False\n",
      "frame_number: 236/361, detected: True\n",
      "frame_number: 237/361, detected: True\n",
      "frame_number: 238/361, detected: True\n",
      "frame_number: 239/361, detected: True\n",
      "frame_number: 240/361, detected: True\n",
      "frame_number: 241/361, detected: True\n",
      "frame_number: 242/361, detected: True\n",
      "frame_number: 243/361, detected: True\n",
      "frame_number: 244/361, detected: True\n",
      "frame_number: 245/361, detected: True\n",
      "frame_number: 246/361, detected: True\n",
      "frame_number: 247/361, detected: True\n",
      "frame_number: 248/361, detected: True\n",
      "frame_number: 249/361, detected: True\n",
      "frame_number: 250/361, detected: True\n",
      "frame_number: 251/361, detected: True\n",
      "frame_number: 252/361, detected: True\n",
      "frame_number: 253/361, detected: True\n",
      "frame_number: 254/361, detected: True\n",
      "frame_number: 255/361, detected: True\n",
      "frame_number: 256/361, detected: True\n",
      "frame_number: 257/361, detected: True\n",
      "frame_number: 258/361, detected: True\n",
      "frame_number: 259/361, detected: True\n",
      "frame_number: 260/361, detected: True\n",
      "frame_number: 261/361, detected: True\n",
      "frame_number: 262/361, detected: True\n",
      "frame_number: 263/361, detected: True\n",
      "frame_number: 264/361, detected: True\n",
      "frame_number: 265/361, detected: True\n",
      "frame_number: 266/361, detected: True\n",
      "frame_number: 267/361, detected: True\n",
      "frame_number: 268/361, detected: True\n",
      "frame_number: 269/361, detected: True\n",
      "271 271 273 {8: 'bounce', 17: 'shot', 64: 'bounce', 74: 'shot', 102: 'bounce', 114: 'shot', 145: 'bounce', 161: 'shot', 178: 'bounce', 193: 'shot', 219: 'bounce', 228: 'shot', 254: 'bounce', 265: 'shot'}\n",
      "frame_number: 270/361, detected: True\n",
      "frame_number: 271/361, detected: True\n",
      "frame_number: 272/361, detected: True\n",
      "frame_number: 273/361, detected: True\n",
      "frame_number: 274/361, detected: True\n",
      "frame_number: 275/361, detected: True\n",
      "frame_number: 276/361, detected: True\n",
      "frame_number: 277/361, detected: True\n",
      "frame_number: 278/361, detected: True\n",
      "frame_number: 279/361, detected: True\n",
      "frame_number: 280/361, detected: True\n",
      "frame_number: 281/361, detected: True\n",
      "frame_number: 282/361, detected: True\n",
      "frame_number: 283/361, detected: True\n",
      "frame_number: 284/361, detected: True\n",
      "frame_number: 285/361, detected: True\n",
      "frame_number: 286/361, detected: True\n",
      "frame_number: 287/361, detected: True\n",
      "frame_number: 288/361, detected: True\n",
      "frame_number: 289/361, detected: True\n",
      "frame_number: 290/361, detected: True\n",
      "frame_number: 291/361, detected: True\n",
      "frame_number: 292/361, detected: True\n",
      "frame_number: 293/361, detected: True\n",
      "frame_number: 294/361, detected: True\n",
      "frame_number: 295/361, detected: True\n",
      "frame_number: 296/361, detected: True\n",
      "frame_number: 297/361, detected: True\n",
      "frame_number: 298/361, detected: True\n",
      "frame_number: 299/361, detected: True\n",
      "301 301 303 {8: 'bounce', 17: 'shot', 64: 'bounce', 74: 'shot', 102: 'bounce', 114: 'shot', 145: 'bounce', 161: 'shot', 178: 'bounce', 193: 'shot', 219: 'bounce', 228: 'shot', 254: 'bounce', 265: 'shot', 284: 'bounce', 296: 'shot'}\n",
      "frame_number: 300/361, detected: True\n",
      "frame_number: 301/361, detected: True\n",
      "frame_number: 302/361, detected: True\n",
      "frame_number: 303/361, detected: True\n",
      "frame_number: 304/361, detected: True\n",
      "frame_number: 305/361, detected: True\n",
      "frame_number: 306/361, detected: True\n",
      "frame_number: 307/361, detected: True\n",
      "frame_number: 308/361, detected: True\n",
      "frame_number: 309/361, detected: True\n",
      "frame_number: 310/361, detected: True\n",
      "frame_number: 311/361, detected: True\n",
      "frame_number: 312/361, detected: True\n",
      "frame_number: 313/361, detected: True\n",
      "frame_number: 314/361, detected: True\n",
      "frame_number: 315/361, detected: True\n",
      "frame_number: 316/361, detected: True\n",
      "frame_number: 317/361, detected: True\n",
      "frame_number: 318/361, detected: True\n",
      "frame_number: 319/361, detected: True\n",
      "frame_number: 320/361, detected: True\n",
      "frame_number: 321/361, detected: True\n",
      "frame_number: 322/361, detected: True\n",
      "frame_number: 323/361, detected: True\n",
      "frame_number: 324/361, detected: True\n",
      "frame_number: 325/361, detected: True\n",
      "frame_number: 326/361, detected: True\n",
      "frame_number: 327/361, detected: True\n",
      "frame_number: 328/361, detected: True\n",
      "frame_number: 329/361, detected: True\n",
      "331 331 333 {8: 'bounce', 17: 'shot', 64: 'bounce', 74: 'shot', 102: 'bounce', 114: 'shot', 145: 'bounce', 161: 'shot', 178: 'bounce', 193: 'shot', 219: 'bounce', 228: 'shot', 254: 'bounce', 265: 'shot', 284: 'bounce', 296: 'shot', 317: 'bounce'}\n",
      "frame_number: 330/361, detected: True\n",
      "frame_number: 331/361, detected: True\n",
      "frame_number: 332/361, detected: True\n",
      "frame_number: 333/361, detected: False\n",
      "frame_number: 334/361, detected: True\n",
      "frame_number: 335/361, detected: True\n",
      "frame_number: 336/361, detected: True\n",
      "frame_number: 337/361, detected: True\n",
      "frame_number: 338/361, detected: True\n",
      "frame_number: 339/361, detected: True\n",
      "frame_number: 340/361, detected: True\n",
      "frame_number: 341/361, detected: True\n",
      "frame_number: 342/361, detected: True\n",
      "frame_number: 343/361, detected: True\n",
      "frame_number: 344/361, detected: True\n",
      "frame_number: 345/361, detected: True\n",
      "frame_number: 346/361, detected: True\n",
      "frame_number: 347/361, detected: True\n",
      "frame_number: 348/361, detected: True\n",
      "frame_number: 349/361, detected: True\n",
      "frame_number: 350/361, detected: True\n",
      "frame_number: 351/361, detected: True\n",
      "frame_number: 352/361, detected: True\n",
      "frame_number: 353/361, detected: True\n",
      "frame_number: 354/361, detected: True\n",
      "frame_number: 355/361, detected: True\n",
      "frame_number: 356/361, detected: True\n",
      "frame_number: 357/361, detected: True\n",
      "frame_number: 358/361, detected: True\n",
      "frame_number: 359/361, detected: True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "video_input_path = 'd:/tennis_v2/test_02.mp4'\n",
    "file_name= video_input_path.split('/')[-1]\n",
    "video_output_path = 'd:/tennis_v2/inference/HRnetv3_30f_' + file_name\n",
    "output_csv_path = 'd:/tennis_v2/inference/HRnetv3_30f_' + file_name + '.csv'\n",
    "\n",
    "run_inference(video_input_path, video_output_path, output_csv_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

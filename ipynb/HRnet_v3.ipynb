{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(\"D:/tennis_v2/\")\n",
    "\n",
    "import cv2\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from model.wasb import HRNet\n",
    "from utils.interpolater import TrajectoryInterpolator\n",
    "from utils.kalman_filter import KalmanFilter\n",
    "from utils.draw import Draw_video\n",
    "from utils.utils import prepare_json, load_config\n",
    "from utils.camera_home_graph import undistort_image\n",
    "from assets.bounce import detect_bounces, draw_cross\n",
    "from assets.person_detector import PersonDetector\n",
    "import websocket\n",
    "import requests\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Constants and Configuration ---\n",
    "CURRENT_DIR = 'D:/tennis_v2/'\n",
    "# BOUNCE_DETECTOR_PATH = f\"{CURRENT_DIR}/weights/ctb_regr_bounce.cbm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = 'D:/tennis_v2/'\n",
    "\n",
    "def preprocess_frame(frame, transform):\n",
    "    return transform(frame)\n",
    "\n",
    "def predict_ball_position(prev_positions, width, height):\n",
    "    if len(prev_positions) < 3:\n",
    "        return None\n",
    "    p_t = prev_positions[-1]\n",
    "    a_t = p_t - 2 * prev_positions[-2] + prev_positions[-3]\n",
    "    v_t = p_t - prev_positions[-2] + a_t\n",
    "    predicted_position = p_t + v_t + 0.5 * a_t\n",
    "    predicted_position = np.clip(predicted_position, [0, 0], [width, height])\n",
    "    return predicted_position\n",
    "\n",
    "def run_inference(input_path, output_path=\"\", output_csv_path=\"\", overlay=False):\n",
    "    # load config\n",
    "    config = load_config(f\"{CURRENT_DIR}/config.yaml\")\n",
    "\n",
    "    # send json data socket\n",
    "    ws = websocket.WebSocket()\n",
    "    ws.connect(config['socket_url'])\n",
    "\n",
    "    # cap url address\n",
    "    response  = requests.get(config['cap_url'])\n",
    "    if response.status_code == 200:   \n",
    "        rtmp_addr = response.json()['data']['videoUrl']\n",
    "        print(f'success get the camera: {rtmp_addr}')\n",
    "    else:\n",
    "        print(f'Error: {response.status_code}')\n",
    "\n",
    "    # cuda\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "\n",
    "    # transform input image\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize((config['inp_height'], config['inp_width'])),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "    # track tennis ball model(HRNet)\n",
    "    model = HRNet(cfg=config).to(device)\n",
    "    checkpoint = torch.load(CURRENT_DIR + config['model_path'], map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'], strict=True)\n",
    "    model.eval()\n",
    "\n",
    "    # # detect people model\n",
    "    # person_model = PersonDetector()\n",
    "\n",
    "    # read input video\n",
    "    cap = cv2.VideoCapture(input_path)   # input_path\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    print(f'success connect camera, the video： {width} X {height}, FPS: {fps}')\n",
    "\n",
    "    base_name = os.path.splitext(os.path.basename(input_path))[0]\n",
    "    if output_path == \"\":\n",
    "        output_video_path = os.path.join(os.path.dirname(output_path))\n",
    "    else:\n",
    "        output_video_path = os.path.join(output_path)\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))   # fps\n",
    "    print(output_video_path)\n",
    "    frame_number = 0\n",
    "    frames_buffer = []\n",
    "    # frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    # detect people\n",
    "    frame_number_outer = 0\n",
    "    player1_data = []\n",
    "    player2_data = []\n",
    "\n",
    "    # kalman\n",
    "    kf = KalmanFilter()\n",
    "    kf_ratio_range = 1\n",
    "    kf_width_range = 8\n",
    "\n",
    "    interpolator = TrajectoryInterpolator()\n",
    "    need_interpolator = False\n",
    "    interpolator_ranage = 10\n",
    "    interpolator_count = []\n",
    "    interpolator_start_frame = None\n",
    "\n",
    "\n",
    "    # bounce\n",
    "    stable_detect = []\n",
    "    coordinate_history = []\n",
    "    frame_history = []   # save the frame, because some frame can not detect the ball, have to predict (x, y) by the context\n",
    "    \n",
    "    prev_positions = [] # for blob select\n",
    "    visited = {}\n",
    "\n",
    "    # draw\n",
    "    draw_video = Draw_video()\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        \"\"\"undistort_image \"\"\"\n",
    "        # frame = undistort_image(frame)\n",
    "\n",
    "        frames_buffer.append(frame)\n",
    "        frame_history.append(frame)\n",
    "\n",
    "\n",
    "        #####################################################################################################################\n",
    "        ########################################           detect people               ######################################\n",
    "        #####################################################################################################################\n",
    "\n",
    "        # player_result = person_model.track_players(frame, frame_number_outer)\n",
    "        # x1, y1, x2, y2, x3, y3, x4, y4 = player_result[1:]\n",
    "        # player1_data.append([x1, y1, x2, y2])\n",
    "        # player2_data.append([x3, y3, x4, y4])\n",
    "        # frame_number_outer += 1\n",
    "\n",
    "        # cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "        # cv2.rectangle(frame, (x3, y3), (x4, y4), (0, 0, 255), 2)\n",
    "\n",
    "        #####################################################################################################################\n",
    "        ########################################           detect tennis ball          ######################################\n",
    "        #####################################################################################################################\n",
    "\n",
    "        if len(frames_buffer) == config['frames_in']:\n",
    "            # Preprocess the frames\n",
    "            frames_processed = [preprocess_frame(f, transform) for f in frames_buffer]\n",
    "            input_tensor = torch.cat(frames_processed, dim=0).unsqueeze(0).to(device)\n",
    "\n",
    "            # Perform inference\n",
    "            with torch.no_grad():\n",
    "                outputs = model(input_tensor)[0]  # Get the raw logits\n",
    "\n",
    "            detected = False\n",
    "            center_x, center_y, confidence = 0, 0, 0\n",
    "\n",
    "            for i in range(config['frames_out']):\n",
    "                output = outputs[0][i]\n",
    "                # Post-process the output\n",
    "                output = torch.sigmoid(output)  # Apply sigmoid to the output to get probabilities\n",
    "                heatmap = output.squeeze().cpu().numpy()\n",
    "                # print(output. shape, heatmap.shape)\n",
    "\n",
    "                heatmap = cv2.resize(heatmap, (width, height), interpolation=cv2.INTER_LINEAR)\n",
    "                heatmap = (heatmap > 0.5).astype(np.float32) * heatmap\n",
    "\n",
    "                # Find connected components\n",
    "                num_labels, labels_im, stats, centroids = cv2.connectedComponentsWithStats((heatmap > 0).astype(np.uint8), connectivity=8)\n",
    "\n",
    "                # Calculate centers of blobs\n",
    "                blob_centers = []\n",
    "                for j in range(1, num_labels):  # Skip the background label 0\n",
    "                    mask = labels_im == j\n",
    "                    blob_sum = heatmap[mask].sum()\n",
    "                    if blob_sum > 0:\n",
    "                        center_x = np.sum(np.where(mask)[1] * heatmap[mask]) / blob_sum\n",
    "                        center_y = np.sum(np.where(mask)[0] * heatmap[mask]) / blob_sum\n",
    "                        blob_centers.append((center_x, center_y, blob_sum))\n",
    "                    \n",
    "                if blob_centers:\n",
    "                    predicted_position = predict_ball_position(prev_positions, width, height)\n",
    "                    if predicted_position is not None:\n",
    "                        # Select the blob closest to the predicted position\n",
    "                        distances = [np.sqrt((x - predicted_position[0]) ** 2 + (y - predicted_position[1]) ** 2) for x, y, _ in blob_centers]\n",
    "                        closest_blob_idx = np.argmin(distances)\n",
    "                        center_x, center_y, confidence = blob_centers[closest_blob_idx]\n",
    "                    else:\n",
    "                        # Select the blob with the highest confidence if no prediction is available\n",
    "                        blob_centers.sort(key=lambda x: x[2], reverse=True)\n",
    "                        center_x, center_y, confidence = blob_centers[0]\n",
    "                    detected = True\n",
    "                    stable_detect.append(detected)\n",
    "                    prev_positions.append(np.array([center_x, center_y]))\n",
    "                    if len(prev_positions) > 3:\n",
    "                        prev_positions.pop(0)\n",
    "                \n",
    "                \n",
    "                \"\"\" if the frame can not detect the tennis, it will wait until the detect comeout 3 times and then fit the miss tennis coordinate \"\"\"\n",
    "                if detected == True :\n",
    "                    coordinate_history.append([center_x, center_y])\n",
    "                    if not need_interpolator:\n",
    "                        color = (0, 255, 0)\n",
    "                        x1, y1, x2, y2 =  kf.xyah_to_xyxy([center_x, center_y, kf_ratio_range, kf_width_range])\n",
    "                        x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "                        text = f\"{confidence:.2f}\"\n",
    "\n",
    "                        \"\"\" draw ball\"\"\"\n",
    "                        # cv2.polylines(overlayed_frame, [points], isClosed=False, color=(0, 255, 255), thickness=2, lineType=cv2.LINE_AA)\n",
    "                        cv2.rectangle(frame_history[-config['frames_out'] + i],(x1, y1), (x2, y2), color, 2)\n",
    "                        cv2.putText(frame_history[-config['frames_out'] + i], text, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "                        \"\"\" draw ball\"\"\"\n",
    "\n",
    "                    else:\n",
    "                        interpolator_count.append([center_x, center_y])\n",
    "                        \n",
    "\n",
    "                else:\n",
    "                    coordinate_history.append([None, None])\n",
    "                    if not need_interpolator:\n",
    "                        need_interpolator = True\n",
    "                        interpolator_start_frame = frame_number\n",
    "                    else:\n",
    "                        interpolator_ranage = min(interpolator_ranage + 1, 20)\n",
    "                    \n",
    "                if need_interpolator:\n",
    "                    if len(interpolator_count) >= interpolator_ranage:\n",
    "                        color = (0, 255, 255)\n",
    "                        inter_trac = interpolator.update_detection_history(coordinate_history, interpolator_start_frame, frame_number)\n",
    "                        for f in range(interpolator_start_frame, frame_number):\n",
    "                            x, y = inter_trac.loc[f, 'x'], inter_trac.loc[f, 'y']\n",
    "                            coordinate_history[f][0], coordinate_history[f][1] =  x, y\n",
    "                            x1, y1, x2, y2 =  kf.xyah_to_xyxy([x, y, kf_ratio_range, kf_width_range])\n",
    "                            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "                            cv2.rectangle(frame_history[f],(x1, y1), (x2, y2), color, 2)\n",
    "                        interpolator_count = []\n",
    "                        need_interpolator = False\n",
    "                        interpolator_ranage = 10\n",
    "                \n",
    "        #####################################################################################################################\n",
    "        ########################################           detect bounce&shot          ######################################\n",
    "        #####################################################################################################################\n",
    "                if frame_number > 0 and (frame_number) % 10 == 0 and len(stable_detect) > 30:   #  and not need_interpolator\n",
    "                    trajectory = pd.DataFrame(coordinate_history, columns=['x', 'y'])\n",
    "                    bounces, ix_5, x,y, ie = detect_bounces(trajectory) # output_csv_path, path_to_video=output_path, path_to_output_video='d:/tennis_v2/inference/HRnetv3_test_03_with_bounce.mp4'\n",
    "                    js_data = prepare_json(frame_number  = frame_number,\n",
    "                                      player1            = player1_data[-30:],\n",
    "                                      player2            = player2_data[-30:],\n",
    "                                      ball_coordinate    = coordinate_history[-30:],\n",
    "                                      ball_event         = ie)\n",
    "                    ws.send(js_data)\n",
    "                    visited = ie\n",
    "                    stable_detect = []\n",
    "                \n",
    "                \"\"\" draw bounce \"\"\"\n",
    "                for key, value in visited.items():\n",
    "                    if frame_number >= key:\n",
    "                        if value == 'shot':\n",
    "                            color = (0, 255, 0) \n",
    "                        elif value== 'bounce':\n",
    "                            color = (0, 0, 255)\n",
    "                        else:\n",
    "                            color = (255, 0, 0)\n",
    "                        draw_cross(frame_history[frame_number], coordinate_history[key][0], coordinate_history[key][1], color=color)\n",
    "                \"\"\" draw bounce \"\"\"\n",
    "\n",
    "                if frame_number > 31:\n",
    "                    cv2.imshow('frame',frame_history[-30])\n",
    "                    \n",
    "                print(f'frame_number: {frame_number}: detected: {detected}')\n",
    "                # print(f'frame_number: {frame_number}/{frame_count}, detected: {detected}')\n",
    "                frame_number += 1\n",
    "            frames_buffer = []  # Clear the buffer for the next set of frames\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "    for frame in frame_history:\n",
    "        out.write(frame)\n",
    "\n",
    "    # Release everything if job is finished\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success get the camera: rtmp://rtmp03open.ys7.com:1935/v3/openlive/BB8121883_1_1?expire=1740734026&id=815270467177811968&t=465c2005e093679e98430835513f82e3d3c8ceee5253fdd34887e54a522f9815&ev=100\n",
      "success connect camera, the video： 1280 X 720, FPS: 29\n",
      "d:/tennis_v2/inference/HRnetv3_30f_iphone_test_02.mp4\n",
      "frame_number: 0: detected: False\n",
      "frame_number: 1: detected: False\n",
      "frame_number: 2: detected: False\n",
      "frame_number: 3: detected: False\n",
      "frame_number: 4: detected: False\n",
      "frame_number: 5: detected: False\n",
      "frame_number: 6: detected: False\n",
      "frame_number: 7: detected: False\n",
      "frame_number: 8: detected: False\n",
      "frame_number: 9: detected: False\n",
      "frame_number: 10: detected: False\n",
      "frame_number: 11: detected: False\n",
      "frame_number: 12: detected: False\n",
      "frame_number: 13: detected: False\n",
      "frame_number: 14: detected: False\n",
      "frame_number: 15: detected: False\n",
      "frame_number: 16: detected: False\n",
      "frame_number: 17: detected: False\n",
      "frame_number: 18: detected: False\n",
      "frame_number: 19: detected: False\n",
      "frame_number: 20: detected: True\n",
      "frame_number: 21: detected: True\n",
      "frame_number: 22: detected: True\n",
      "frame_number: 23: detected: True\n",
      "frame_number: 24: detected: True\n",
      "frame_number: 25: detected: True\n",
      "frame_number: 26: detected: True\n",
      "frame_number: 27: detected: True\n",
      "frame_number: 28: detected: True\n",
      "frame_number: 29: detected: True\n",
      "frame_number: 30: detected: True\n",
      "frame_number: 31: detected: True\n",
      "frame_number: 32: detected: True\n",
      "frame_number: 33: detected: True\n",
      "frame_number: 34: detected: True\n",
      "frame_number: 35: detected: True\n",
      "frame_number: 36: detected: True\n",
      "frame_number: 37: detected: True\n",
      "frame_number: 38: detected: True\n",
      "frame_number: 39: detected: True\n",
      "frame_number: 40: detected: True\n",
      "frame_number: 41: detected: True\n",
      "frame_number: 42: detected: True\n",
      "frame_number: 43: detected: True\n",
      "frame_number: 44: detected: True\n",
      "frame_number: 45: detected: True\n",
      "frame_number: 46: detected: True\n",
      "frame_number: 47: detected: True\n",
      "frame_number: 48: detected: True\n",
      "frame_number: 49: detected: True\n",
      "frame_number: 50: detected: True\n",
      "frame_number: 51: detected: True\n",
      "frame_number: 52: detected: True\n",
      "frame_number: 53: detected: True\n",
      "frame_number: 54: detected: True\n",
      "frame_number: 55: detected: True\n",
      "frame_number: 56: detected: True\n",
      "frame_number: 57: detected: True\n",
      "frame_number: 58: detected: True\n",
      "frame_number: 59: detected: True\n",
      "frame_number: 60: detected: True\n",
      "frame_number: 61: detected: True\n",
      "frame_number: 62: detected: True\n",
      "frame_number: 63: detected: True\n",
      "frame_number: 64: detected: True\n",
      "frame_number: 65: detected: True\n",
      "frame_number: 66: detected: False\n",
      "frame_number: 67: detected: False\n",
      "frame_number: 68: detected: False\n",
      "frame_number: 69: detected: True\n",
      "frame_number: 70: detected: True\n",
      "frame_number: 71: detected: True\n",
      "frame_number: 72: detected: True\n",
      "frame_number: 73: detected: True\n",
      "frame_number: 74: detected: True\n",
      "frame_number: 75: detected: True\n",
      "frame_number: 76: detected: True\n",
      "frame_number: 77: detected: True\n",
      "frame_number: 78: detected: True\n",
      "frame_number: 79: detected: True\n",
      "frame_number: 80: detected: True\n",
      "frame_number: 81: detected: True\n",
      "frame_number: 82: detected: True\n",
      "frame_number: 83: detected: True\n",
      "frame_number: 84: detected: True\n",
      "frame_number: 85: detected: True\n",
      "frame_number: 86: detected: True\n",
      "frame_number: 87: detected: True\n",
      "frame_number: 88: detected: True\n",
      "frame_number: 89: detected: True\n",
      "frame_number: 90: detected: True\n",
      "frame_number: 91: detected: True\n",
      "frame_number: 92: detected: True\n",
      "frame_number: 93: detected: True\n",
      "frame_number: 94: detected: True\n",
      "frame_number: 95: detected: True\n",
      "frame_number: 96: detected: True\n",
      "frame_number: 97: detected: True\n",
      "frame_number: 98: detected: True\n",
      "frame_number: 99: detected: True\n",
      "frame_number: 100: detected: True\n",
      "frame_number: 101: detected: True\n",
      "frame_number: 102: detected: True\n",
      "frame_number: 103: detected: True\n",
      "frame_number: 104: detected: True\n",
      "frame_number: 105: detected: True\n",
      "frame_number: 106: detected: True\n",
      "frame_number: 107: detected: True\n",
      "frame_number: 108: detected: True\n",
      "frame_number: 109: detected: True\n",
      "frame_number: 110: detected: True\n",
      "frame_number: 111: detected: True\n",
      "frame_number: 112: detected: True\n",
      "frame_number: 113: detected: True\n",
      "frame_number: 114: detected: True\n",
      "frame_number: 115: detected: True\n",
      "frame_number: 116: detected: True\n",
      "frame_number: 117: detected: True\n",
      "frame_number: 118: detected: True\n",
      "frame_number: 119: detected: True\n",
      "frame_number: 120: detected: True\n",
      "frame_number: 121: detected: True\n",
      "frame_number: 122: detected: True\n",
      "frame_number: 123: detected: True\n",
      "frame_number: 124: detected: True\n",
      "frame_number: 125: detected: True\n",
      "frame_number: 126: detected: True\n",
      "frame_number: 127: detected: True\n",
      "frame_number: 128: detected: True\n",
      "frame_number: 129: detected: True\n",
      "frame_number: 130: detected: True\n",
      "frame_number: 131: detected: True\n",
      "frame_number: 132: detected: False\n",
      "frame_number: 133: detected: True\n",
      "frame_number: 134: detected: True\n",
      "frame_number: 135: detected: True\n",
      "frame_number: 136: detected: True\n",
      "frame_number: 137: detected: True\n",
      "frame_number: 138: detected: True\n",
      "frame_number: 139: detected: True\n",
      "frame_number: 140: detected: True\n",
      "frame_number: 141: detected: True\n",
      "frame_number: 142: detected: True\n",
      "frame_number: 143: detected: True\n",
      "frame_number: 144: detected: True\n",
      "frame_number: 145: detected: True\n",
      "frame_number: 146: detected: True\n",
      "frame_number: 147: detected: True\n",
      "frame_number: 148: detected: True\n",
      "frame_number: 149: detected: True\n",
      "frame_number: 150: detected: True\n",
      "frame_number: 151: detected: True\n",
      "frame_number: 152: detected: True\n",
      "frame_number: 153: detected: True\n",
      "frame_number: 154: detected: True\n",
      "frame_number: 155: detected: True\n",
      "frame_number: 156: detected: True\n",
      "frame_number: 157: detected: True\n",
      "frame_number: 158: detected: True\n",
      "frame_number: 159: detected: True\n",
      "frame_number: 160: detected: True\n",
      "frame_number: 161: detected: True\n",
      "frame_number: 162: detected: True\n",
      "frame_number: 163: detected: True\n",
      "frame_number: 164: detected: True\n",
      "frame_number: 165: detected: True\n",
      "frame_number: 166: detected: True\n",
      "frame_number: 167: detected: True\n",
      "frame_number: 168: detected: True\n",
      "frame_number: 169: detected: True\n",
      "frame_number: 170: detected: True\n",
      "frame_number: 171: detected: True\n",
      "frame_number: 172: detected: True\n",
      "frame_number: 173: detected: True\n",
      "frame_number: 174: detected: True\n",
      "frame_number: 175: detected: True\n",
      "frame_number: 176: detected: True\n",
      "frame_number: 177: detected: True\n",
      "frame_number: 178: detected: True\n",
      "frame_number: 179: detected: True\n",
      "frame_number: 180: detected: False\n",
      "frame_number: 181: detected: False\n",
      "frame_number: 182: detected: False\n",
      "frame_number: 183: detected: True\n",
      "frame_number: 184: detected: True\n",
      "frame_number: 185: detected: True\n",
      "frame_number: 186: detected: True\n",
      "frame_number: 187: detected: True\n",
      "frame_number: 188: detected: True\n",
      "frame_number: 189: detected: True\n",
      "frame_number: 190: detected: True\n",
      "frame_number: 191: detected: True\n",
      "frame_number: 192: detected: True\n",
      "frame_number: 193: detected: True\n",
      "frame_number: 194: detected: True\n",
      "frame_number: 195: detected: True\n",
      "frame_number: 196: detected: True\n",
      "frame_number: 197: detected: True\n",
      "frame_number: 198: detected: True\n",
      "frame_number: 199: detected: True\n",
      "frame_number: 200: detected: True\n",
      "frame_number: 201: detected: True\n",
      "frame_number: 202: detected: True\n",
      "frame_number: 203: detected: True\n",
      "frame_number: 204: detected: True\n",
      "frame_number: 205: detected: True\n",
      "frame_number: 206: detected: True\n",
      "frame_number: 207: detected: False\n",
      "frame_number: 208: detected: False\n",
      "frame_number: 209: detected: False\n",
      "frame_number: 210: detected: False\n",
      "frame_number: 211: detected: False\n",
      "frame_number: 212: detected: False\n",
      "frame_number: 213: detected: True\n",
      "frame_number: 214: detected: True\n",
      "frame_number: 215: detected: True\n",
      "frame_number: 216: detected: True\n",
      "frame_number: 217: detected: True\n",
      "frame_number: 218: detected: True\n",
      "frame_number: 219: detected: True\n",
      "frame_number: 220: detected: True\n",
      "frame_number: 221: detected: True\n",
      "frame_number: 222: detected: True\n",
      "frame_number: 223: detected: True\n",
      "frame_number: 224: detected: True\n",
      "frame_number: 225: detected: True\n",
      "frame_number: 226: detected: True\n",
      "frame_number: 227: detected: True\n",
      "frame_number: 228: detected: True\n",
      "frame_number: 229: detected: True\n",
      "frame_number: 230: detected: True\n",
      "frame_number: 231: detected: True\n",
      "frame_number: 232: detected: True\n",
      "frame_number: 233: detected: True\n",
      "frame_number: 234: detected: True\n",
      "frame_number: 235: detected: True\n",
      "frame_number: 236: detected: True\n",
      "frame_number: 237: detected: True\n",
      "frame_number: 238: detected: True\n",
      "frame_number: 239: detected: True\n",
      "frame_number: 240: detected: True\n",
      "frame_number: 241: detected: True\n",
      "frame_number: 242: detected: True\n",
      "frame_number: 243: detected: True\n",
      "frame_number: 244: detected: True\n",
      "frame_number: 245: detected: True\n",
      "frame_number: 246: detected: True\n",
      "frame_number: 247: detected: True\n",
      "frame_number: 248: detected: True\n",
      "frame_number: 249: detected: False\n",
      "frame_number: 250: detected: False\n",
      "frame_number: 251: detected: False\n",
      "frame_number: 252: detected: False\n",
      "frame_number: 253: detected: False\n",
      "frame_number: 254: detected: False\n",
      "frame_number: 255: detected: True\n",
      "frame_number: 256: detected: True\n",
      "frame_number: 257: detected: True\n",
      "frame_number: 258: detected: True\n",
      "frame_number: 259: detected: True\n",
      "frame_number: 260: detected: True\n",
      "frame_number: 261: detected: True\n",
      "frame_number: 262: detected: True\n",
      "frame_number: 263: detected: True\n",
      "frame_number: 264: detected: True\n",
      "frame_number: 265: detected: True\n",
      "frame_number: 266: detected: True\n",
      "frame_number: 267: detected: True\n",
      "frame_number: 268: detected: True\n",
      "frame_number: 269: detected: True\n",
      "frame_number: 270: detected: False\n",
      "frame_number: 271: detected: False\n",
      "frame_number: 272: detected: False\n",
      "frame_number: 273: detected: False\n",
      "frame_number: 274: detected: False\n",
      "frame_number: 275: detected: False\n",
      "frame_number: 276: detected: True\n",
      "frame_number: 277: detected: True\n",
      "frame_number: 278: detected: True\n",
      "frame_number: 279: detected: True\n",
      "frame_number: 280: detected: True\n",
      "frame_number: 281: detected: True\n",
      "frame_number: 282: detected: True\n",
      "frame_number: 283: detected: True\n",
      "frame_number: 284: detected: True\n",
      "frame_number: 285: detected: True\n",
      "frame_number: 286: detected: True\n",
      "frame_number: 287: detected: True\n",
      "frame_number: 288: detected: True\n",
      "frame_number: 289: detected: True\n",
      "frame_number: 290: detected: True\n",
      "frame_number: 291: detected: True\n",
      "frame_number: 292: detected: True\n",
      "frame_number: 293: detected: True\n",
      "frame_number: 294: detected: True\n",
      "frame_number: 295: detected: True\n",
      "frame_number: 296: detected: True\n",
      "frame_number: 297: detected: True\n",
      "frame_number: 298: detected: True\n",
      "frame_number: 299: detected: True\n",
      "frame_number: 300: detected: True\n",
      "frame_number: 301: detected: True\n",
      "frame_number: 302: detected: True\n",
      "frame_number: 303: detected: True\n",
      "frame_number: 304: detected: True\n",
      "frame_number: 305: detected: True\n",
      "frame_number: 306: detected: True\n",
      "frame_number: 307: detected: True\n",
      "frame_number: 308: detected: True\n",
      "frame_number: 309: detected: True\n",
      "frame_number: 310: detected: True\n",
      "frame_number: 311: detected: True\n",
      "frame_number: 312: detected: True\n",
      "frame_number: 313: detected: True\n",
      "frame_number: 314: detected: True\n",
      "frame_number: 315: detected: True\n",
      "frame_number: 316: detected: True\n",
      "frame_number: 317: detected: True\n",
      "frame_number: 318: detected: True\n",
      "frame_number: 319: detected: True\n",
      "frame_number: 320: detected: True\n",
      "frame_number: 321: detected: True\n",
      "frame_number: 322: detected: True\n",
      "frame_number: 323: detected: True\n",
      "frame_number: 324: detected: True\n",
      "frame_number: 325: detected: True\n",
      "frame_number: 326: detected: True\n",
      "frame_number: 327: detected: True\n",
      "frame_number: 328: detected: True\n",
      "frame_number: 329: detected: True\n",
      "frame_number: 330: detected: True\n",
      "frame_number: 331: detected: True\n",
      "frame_number: 332: detected: True\n",
      "frame_number: 333: detected: True\n",
      "frame_number: 334: detected: True\n",
      "frame_number: 335: detected: True\n",
      "frame_number: 336: detected: True\n",
      "frame_number: 337: detected: True\n",
      "frame_number: 338: detected: True\n",
      "frame_number: 339: detected: True\n",
      "frame_number: 340: detected: True\n",
      "frame_number: 341: detected: True\n",
      "frame_number: 342: detected: True\n",
      "frame_number: 343: detected: True\n",
      "frame_number: 344: detected: True\n",
      "frame_number: 345: detected: True\n",
      "frame_number: 346: detected: True\n",
      "frame_number: 347: detected: True\n",
      "frame_number: 348: detected: True\n",
      "frame_number: 349: detected: True\n",
      "frame_number: 350: detected: True\n",
      "frame_number: 351: detected: True\n",
      "frame_number: 352: detected: True\n",
      "frame_number: 353: detected: True\n",
      "frame_number: 354: detected: True\n",
      "frame_number: 355: detected: True\n",
      "frame_number: 356: detected: True\n",
      "frame_number: 357: detected: True\n",
      "frame_number: 358: detected: True\n",
      "frame_number: 359: detected: True\n",
      "frame_number: 360: detected: True\n",
      "frame_number: 361: detected: True\n",
      "frame_number: 362: detected: True\n",
      "frame_number: 363: detected: True\n",
      "frame_number: 364: detected: True\n",
      "frame_number: 365: detected: True\n",
      "frame_number: 366: detected: True\n",
      "frame_number: 367: detected: True\n",
      "frame_number: 368: detected: True\n",
      "frame_number: 369: detected: True\n",
      "frame_number: 370: detected: True\n",
      "frame_number: 371: detected: True\n",
      "frame_number: 372: detected: True\n",
      "frame_number: 373: detected: True\n",
      "frame_number: 374: detected: True\n",
      "frame_number: 375: detected: False\n",
      "frame_number: 376: detected: True\n",
      "frame_number: 377: detected: True\n",
      "frame_number: 378: detected: True\n",
      "frame_number: 379: detected: True\n",
      "frame_number: 380: detected: True\n",
      "frame_number: 381: detected: True\n",
      "frame_number: 382: detected: True\n",
      "frame_number: 383: detected: True\n",
      "frame_number: 384: detected: False\n",
      "frame_number: 385: detected: False\n",
      "frame_number: 386: detected: False\n",
      "frame_number: 387: detected: True\n",
      "frame_number: 388: detected: True\n",
      "frame_number: 389: detected: True\n",
      "frame_number: 390: detected: False\n",
      "frame_number: 391: detected: False\n",
      "frame_number: 392: detected: False\n",
      "frame_number: 393: detected: False\n",
      "frame_number: 394: detected: False\n",
      "frame_number: 395: detected: False\n",
      "frame_number: 396: detected: False\n",
      "frame_number: 397: detected: False\n",
      "frame_number: 398: detected: False\n",
      "frame_number: 399: detected: False\n",
      "frame_number: 400: detected: False\n",
      "frame_number: 401: detected: False\n",
      "frame_number: 402: detected: False\n",
      "frame_number: 403: detected: False\n",
      "frame_number: 404: detected: False\n",
      "frame_number: 405: detected: False\n",
      "frame_number: 406: detected: False\n",
      "frame_number: 407: detected: False\n",
      "frame_number: 408: detected: True\n",
      "frame_number: 409: detected: True\n",
      "frame_number: 410: detected: True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "video_input_path = 'd:/tennis_v2/iphone_test_02.mp4'\n",
    "file_name= video_input_path.split('/')[-1]\n",
    "video_output_path = 'd:/tennis_v2/inference/HRnetv3_30f_' + file_name\n",
    "output_csv_path = 'd:/tennis_v2/inference/HRnetv3_30f_' + file_name + '.csv'\n",
    "\n",
    "run_inference(video_input_path, video_output_path, output_csv_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
